{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DuLtCJIUGILB"
   },
   "source": [
    "필요한 라이브러리 설치와 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73151,
     "status": "ok",
     "timestamp": 1701439109754,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "c9hGhDX1S32U",
    "outputId": "be977e92-2eb7-4675-b1aa-37774ccc176c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.8/site-packages (0.1.99)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: mxnet in /opt/conda/lib/python3.8/site-packages (1.9.1)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /opt/conda/lib/python3.8/site-packages (from mxnet) (1.21.2)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /opt/conda/lib/python3.8/site-packages (from mxnet) (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (1.26.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: gluonnlp==0.8.0 in /opt/conda/lib/python3.8/site-packages (0.8.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from gluonnlp==0.8.0) (1.21.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (4.62.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/conda/lib/python3.8/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (1.10.0a0+3fd9dcf)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch) (3.10.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.8/site-packages (0.1.99)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2021.8.28)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install sentencepiece\n",
    "# !pip install mxnet\n",
    "# !pip install gluonnlp==0.8.0\n",
    "# !pip install tqdm pandas\n",
    "# !pip install torch\n",
    "# !pip install sentencepiece\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10010,
     "status": "ok",
     "timestamp": 1701439226384,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "BMnW_BsAsNgM",
    "outputId": "7d9ae69d-01d7-4d75-9c02-9063b46ddb75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kobert_tokenizer\n",
      "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-fdeswrqf/kobert-tokenizer_93f7dd0a3ec7402a89e374cbefd5a3f3\n",
      "  Running command git clone -q https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-fdeswrqf/kobert-tokenizer_93f7dd0a3ec7402a89e374cbefd5a3f3\n",
      "  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 14677,
     "status": "ok",
     "timestamp": 1701450758313,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "yNLDld2rsdMZ"
   },
   "outputs": [],
   "source": [
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "from transformers import BertModel\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1701450758313,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "PYQLAuQbseaL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7033,
     "status": "ok",
     "timestamp": 1701450765343,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "qpLTmU5rsfg_",
    "outputId": "b777ed36-315e-4ed5-ad76-dafec6b628a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/mxnet/optimizer/optimizer.py:163: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
      "  warnings.warn('WARNING: New optimizer %s.%s is overriding '\n"
     ]
    }
   ],
   "source": [
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1701450767357,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "JjIuDsvCsm__"
   },
   "outputs": [],
   "source": [
    "device_type = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWTGOdYwGQWg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home2/jh981017/myubai/machinelearning'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_G7yhjvGQks"
   },
   "source": [
    "각 폴더에서 텍스트 저장한 엑셀파일 위치 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1701450767357,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "SmQmGrJTswLn",
    "outputId": "e0764914-0bf2-4315-d218-863e6ba13d4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home2/jh981017/myubai/NaverNews/economy',\n",
       " '/home2/jh981017/myubai/NaverNews/life',\n",
       " '/home2/jh981017/myubai/NaverNews/politics',\n",
       " '/home2/jh981017/myubai/NaverNews/science',\n",
       " '/home2/jh981017/myubai/NaverNews/society',\n",
       " '/home2/jh981017/myubai/NaverNews/world']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_folders = glob.glob('/home2/jh981017/myubai/NaverNews/*')\n",
    "section_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1701450767357,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "up6B4YI0vddl",
    "outputId": "1e05361a-eb0c-40de-9add-4e963dcabe1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['economy', 'life', 'politics', 'science', 'society', 'world']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = '/home2/jh981017/myubai/NaverNews'\n",
    "sections = os.listdir(root)\n",
    "sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701450767357,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "VXTceACpvmON",
    "outputId": "19320275-d1df-4a25-c655-850ca43a7c67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home2/jh981017/myubai/NaverNews/economy/economytext1.xlsx',\n",
       " '/home2/jh981017/myubai/NaverNews/life/lifetext1.xlsx',\n",
       " '/home2/jh981017/myubai/NaverNews/politics/politicstext1.xlsx',\n",
       " '/home2/jh981017/myubai/NaverNews/science/sciencetext1.xlsx',\n",
       " '/home2/jh981017/myubai/NaverNews/society/societytext1.xlsx',\n",
       " '/home2/jh981017/myubai/NaverNews/world/worldtext1.xlsx']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_paths = []\n",
    "for folder, section in zip(section_folders, sections):\n",
    "  text_path = folder + '/' + section + 'text1' + '.xlsx'\n",
    "  text_paths.append(text_path)\n",
    "\n",
    "text_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45G7x0LpGVgc"
   },
   "source": [
    "각 섹션별 인덱스로 분석에 사용할 텍스트 가져오기, label - y 페어 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6648,
     "status": "ok",
     "timestamp": 1701450780082,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "XUBD-2YoVikW"
   },
   "outputs": [],
   "source": [
    "idx_dictionary = {}\n",
    "\n",
    "for section, text_path in zip(sections, text_paths):\n",
    "  text = pd.read_excel(text_path)\n",
    "  idx_section = list(text['idx'])\n",
    "\n",
    "  idx_dictionary[section] = idx_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1701450786765,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "L9xTPGZLWA5o",
    "outputId": "5623deae-bc50-4067-b78b-c83f3e0dc812"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1888"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_dictionary['economy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701450788070,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "rnJjC1fmvBZk"
   },
   "outputs": [],
   "source": [
    "np.random.seed(602)\n",
    "\n",
    "cv_idx_dictionary = {}\n",
    "\n",
    "for section in sections:\n",
    "  cv_idx_section = list(np.random.choice(idx_dictionary[section], size = 1200, replace = False))\n",
    "  cv_idx_section.sort()\n",
    "\n",
    "  cv_idx_dictionary[section] = cv_idx_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701450788814,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "W6Q47avgwoNz",
    "outputId": "5f388b67-d55e-445c-d663-f8a943ce4f9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_idx_dictionary['economy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 859,
     "status": "ok",
     "timestamp": 1701450790967,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "yUGeb_ucw6Cf"
   },
   "outputs": [],
   "source": [
    "new_idx_dictionary = {}\n",
    "\n",
    "for section in sections:\n",
    "  new_idx_section = [i for i in idx_dictionary[section] if i not in cv_idx_dictionary[section]]\n",
    "\n",
    "  new_idx_dictionary[section] = new_idx_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1701450791451,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "RbqYyKjJxgQk",
    "outputId": "f2207077-4663-4001-b6b4-dcec203e2792"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "688"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_idx_dictionary['economy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "elJJ_2nvv_Kn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "fjXVyrcCERo4"
   },
   "outputs": [],
   "source": [
    "# label_to_y = {section : idx for idx, section in enumerate(sections)}\n",
    "# label_to_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1701450946893,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "OgYBZ7L7z7ti",
    "outputId": "793b94f0-6f36-4061-ff94-b5c10cccfe50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'politics': 0,\n",
       " 'society': 1,\n",
       " 'science': 2,\n",
       " 'life': 3,\n",
       " 'world': 4,\n",
       " 'economy': 5}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_y = {\n",
    "    'politics': 0,\n",
    "    'society': 1,\n",
    "    'science': 2,\n",
    "    'life': 3,\n",
    "    'world': 4,\n",
    "    'economy': 5\n",
    "}\n",
    "label_to_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUOxGpNlGqJz"
   },
   "source": [
    "전체 데이터 : 제목 + 본문 텍스트 (X), 라벨과 일대일대응된 숫자(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2803,
     "status": "ok",
     "timestamp": 1701450950843,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "fO_ZvRgIwhLE",
    "outputId": "846be6ca-5d1f-4b37-9183-a316fcd48d65"
   },
   "outputs": [],
   "source": [
    "cv_data = []\n",
    "new_data = []\n",
    "\n",
    "for section_folder in section_folders:\n",
    "  section = os.path.basename(section_folder)\n",
    "  section_textpath = section_folder + '/' + section + 'text1' + '.xlsx' #정제한걸로했음\n",
    "\n",
    "  section_texts = pd.read_excel(section_textpath)\n",
    "\n",
    "\n",
    "  cv_indicies = cv_idx_dictionary[section]\n",
    "  new_indicies = new_idx_dictionary[section]\n",
    "\n",
    "  # X\n",
    "  cv_condition = section_texts['idx'].isin(cv_indicies)\n",
    "  new_condition = section_texts['idx'].isin(new_indicies)\n",
    "\n",
    "  cv_articles = section_texts.loc[cv_condition, 'title'] + ' ' + section_texts.loc[cv_condition, 'body']\n",
    "  new_articles = section_texts.loc[new_condition, 'title'] + ' ' + section_texts.loc[new_condition, 'body']\n",
    "\n",
    "\n",
    "  # y\n",
    "  y = label_to_y[section]\n",
    "\n",
    "\n",
    "  for cv_idx, cv_article in zip(cv_indicies, cv_articles):\n",
    "    data = []\n",
    "    data.append(cv_idx)\n",
    "    data.append(cv_article)\n",
    "    data.append(y)\n",
    "\n",
    "    cv_data.append(data)\n",
    "\n",
    "  for new_idx, new_article in zip(new_indicies, new_articles):\n",
    "    data = []\n",
    "    data.append(new_idx)\n",
    "    data.append(new_article)\n",
    "    data.append(y)\n",
    "\n",
    "    new_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1701450950843,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "mFH3d8oItXrX",
    "outputId": "540e045e-e261-418e-d94b-fde019b1b153"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7200"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701450951382,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "yiIjDam0Wsw2",
    "outputId": "dd5d1515-36f2-4773-a997-f28c9faaeb10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5720"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCqQSn0U7y55"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1701444976601,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "aAtLqgrL5V_R",
    "outputId": "a080d191-97e7-4715-bf62-20f7b5adf113"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5대은행 가계대출 한달새 3조5000억 늘어...올 들어 최대 폭         5...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>빗썸 부리또 월렛, GBIC 해커톤 대회 성료 [서울=뉴시스]이지영 기자 = 빗썸 ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>농협은행, 연합 플로깅 캠페인으로 ‘ESG’ 실천  NH농협은행(은행장 이석용)은 ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>하나금융, 전 임직원 '모두하나데이'로 ESG 실천  하나금융그룹은 1일 하나금융그...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>윤 대통령이 질타한 '은행 성과급 잔치'는 없었다 최근 수년간 대출 금리 인상 등으...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7195</th>\n",
       "      <td>1910</td>\n",
       "      <td>미국서 2주 이상 실업수당 청구한 사람, 2년 만에 최대         16일(현지...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7196</th>\n",
       "      <td>1912</td>\n",
       "      <td>이스라엘, 알시파 병원에 외신 불러… \"버려진 노트북에 인질 영상\" 주장 팔레스타인...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7197</th>\n",
       "      <td>1913</td>\n",
       "      <td>러 매체, “‘푸틴 신뢰한다’는 한국 청년, 러시아군 자원 입대” 러시아 매체 ‘A...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7198</th>\n",
       "      <td>1914</td>\n",
       "      <td>클린스만호, 싱가포르에 5-0 대승...손흥민 이강인 황희찬 등 공격진 모두 골골골...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>1917</td>\n",
       "      <td>러시아 매체 \"한국 청년, 러시아군 입대… 돈바스 지역 투입\" 러시아 매체가 한국의...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1  2\n",
       "0        3  5대은행 가계대출 한달새 3조5000억 늘어...올 들어 최대 폭         5...  5\n",
       "1        6  빗썸 부리또 월렛, GBIC 해커톤 대회 성료 [서울=뉴시스]이지영 기자 = 빗썸 ...  5\n",
       "2        9  농협은행, 연합 플로깅 캠페인으로 ‘ESG’ 실천  NH농협은행(은행장 이석용)은 ...  5\n",
       "3       13  하나금융, 전 임직원 '모두하나데이'로 ESG 실천  하나금융그룹은 1일 하나금융그...  5\n",
       "4       16  윤 대통령이 질타한 '은행 성과급 잔치'는 없었다 최근 수년간 대출 금리 인상 등으...  5\n",
       "...    ...                                                ... ..\n",
       "7195  1910  미국서 2주 이상 실업수당 청구한 사람, 2년 만에 최대         16일(현지...  4\n",
       "7196  1912  이스라엘, 알시파 병원에 외신 불러… \"버려진 노트북에 인질 영상\" 주장 팔레스타인...  4\n",
       "7197  1913  러 매체, “‘푸틴 신뢰한다’는 한국 청년, 러시아군 자원 입대” 러시아 매체 ‘A...  4\n",
       "7198  1914  클린스만호, 싱가포르에 5-0 대승...손흥민 이강인 황희찬 등 공격진 모두 골골골...  4\n",
       "7199  1917  러시아 매체 \"한국 청년, 러시아군 입대… 돈바스 지역 투입\" 러시아 매체가 한국의...  4\n",
       "\n",
       "[7200 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_data = pd.DataFrame(cv_data)\n",
    "df_cv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAEAchk35rSs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1701444973311,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "PvSmwmk0Bbf0",
    "outputId": "793bfd97-c990-4017-a10a-033f60440ea4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>'살아난 비트코인' 코인 시장 자금 수급 이끌자…디파이·NFT장도 '꿈틀' (서울=...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>부산디지털자산거래소 사업자 선정 돌입 부산시가 ‘부산디지털자산거래소’(BDX)의 설...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>“비트코인 2년 내 2억 원 도달…현재 가격의 4배 폭등” 최근 상승세를 보이는 가...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>국민연금, 카카오 보유목적 ‘일반투자’로…주주권 행사 나서나 [이코노미스트 마켓in...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>배터리 수장 '권영수부회장·지동섭대표'에 쏠린 시선…발언보니 국내 배터리 업계 최고...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5715</th>\n",
       "      <td>1909</td>\n",
       "      <td>러시아, 미국 수교 90주년에 \"언제든 관계 끊길 수도\" 경고 러시아가 미국과 수교...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5716</th>\n",
       "      <td>1911</td>\n",
       "      <td>동료가 준 생일선물, '폭탄'이었다…우크라군 총사령관 참모 사망 [서울경제] 발레리...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5717</th>\n",
       "      <td>1915</td>\n",
       "      <td>\"뉴스? '틱톡'으로 봐요\"…미국인들 이용률 3년 새 '22％→43％' [서울경제]...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5718</th>\n",
       "      <td>1916</td>\n",
       "      <td>한 알 먹고 \"몸이 왜 이러지?\" 병원행…日 '발칵' 뒤집은 이 젤리 16일 일본 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>1918</td>\n",
       "      <td>대만, 미중 정상회담에 \"美, 대만해협 안정 입장 재확인 기뻐\" 조 바이든 미국 대...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5720 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1  2\n",
       "0       10  '살아난 비트코인' 코인 시장 자금 수급 이끌자…디파이·NFT장도 '꿈틀' (서울=...  5\n",
       "1       15  부산디지털자산거래소 사업자 선정 돌입 부산시가 ‘부산디지털자산거래소’(BDX)의 설...  5\n",
       "2       19  “비트코인 2년 내 2억 원 도달…현재 가격의 4배 폭등” 최근 상승세를 보이는 가...  5\n",
       "3       21  국민연금, 카카오 보유목적 ‘일반투자’로…주주권 행사 나서나 [이코노미스트 마켓in...  5\n",
       "4       27  배터리 수장 '권영수부회장·지동섭대표'에 쏠린 시선…발언보니 국내 배터리 업계 최고...  5\n",
       "...    ...                                                ... ..\n",
       "5715  1909  러시아, 미국 수교 90주년에 \"언제든 관계 끊길 수도\" 경고 러시아가 미국과 수교...  4\n",
       "5716  1911  동료가 준 생일선물, '폭탄'이었다…우크라군 총사령관 참모 사망 [서울경제] 발레리...  4\n",
       "5717  1915  \"뉴스? '틱톡'으로 봐요\"…미국인들 이용률 3년 새 '22％→43％' [서울경제]...  4\n",
       "5718  1916  한 알 먹고 \"몸이 왜 이러지?\" 병원행…日 '발칵' 뒤집은 이 젤리 16일 일본 ...  4\n",
       "5719  1918  대만, 미중 정상회담에 \"美, 대만해협 안정 입장 재확인 기뻐\" 조 바이든 미국 대...  4\n",
       "\n",
       "[5720 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_data = pd.DataFrame(new_data)\n",
    "df_new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2X9h40hG7de"
   },
   "source": [
    "KoBERT 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1701445053467,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "goaVn2HqHAOP"
   },
   "outputs": [],
   "source": [
    "class BERTSentenceTransform:\n",
    "    r\"\"\"BERT style data transformation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tokenizer : BERTTokenizer.\n",
    "        Tokenizer for the sentences.\n",
    "    max_seq_length : int.\n",
    "        Maximum sequence length of the sentences.\n",
    "    pad : bool, default True\n",
    "        Whether to pad the sentences to maximum length.\n",
    "    pair : bool, default True\n",
    "        Whether to transform sentences or sentence pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer, max_seq_length,vocab, pad=True, pair=True):\n",
    "        self._tokenizer = tokenizer\n",
    "        self._max_seq_length = max_seq_length\n",
    "        self._pad = pad\n",
    "        self._pair = pair\n",
    "        self._vocab = vocab\n",
    "\n",
    "    def __call__(self, line):\n",
    "        \"\"\"Perform transformation for sequence pairs or single sequences.\n",
    "\n",
    "        The transformation is processed in the following steps:\n",
    "        - tokenize the input sequences\n",
    "        - insert [CLS], [SEP] as necessary\n",
    "        - generate type ids to indicate whether a token belongs to the first\n",
    "        sequence or the second sequence.\n",
    "        - generate valid length\n",
    "\n",
    "        For sequence pairs, the input is a tuple of 2 strings:\n",
    "        text_a, text_b.\n",
    "\n",
    "        Inputs:\n",
    "            text_a: 'is this jacksonville ?'\n",
    "            text_b: 'no it is not'\n",
    "        Tokenization:\n",
    "            text_a: 'is this jack ##son ##ville ?'\n",
    "            text_b: 'no it is not .'\n",
    "        Processed:\n",
    "            tokens: '[CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]'\n",
    "            type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
    "            valid_length: 14\n",
    "\n",
    "        For single sequences, the input is a tuple of single string:\n",
    "        text_a.\n",
    "\n",
    "        Inputs:\n",
    "            text_a: 'the dog is hairy .'\n",
    "        Tokenization:\n",
    "            text_a: 'the dog is hairy .'\n",
    "        Processed:\n",
    "            text_a: '[CLS] the dog is hairy . [SEP]'\n",
    "            type_ids: 0     0   0   0  0     0 0\n",
    "            valid_length: 7\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        line: tuple of str\n",
    "            Input strings. For sequence pairs, the input is a tuple of 2 strings:\n",
    "            (text_a, text_b). For single sequences, the input is a tuple of single\n",
    "            string: (text_a,).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array: input token ids in 'int32', shape (batch_size, seq_length)\n",
    "        np.array: valid length in 'int32', shape (batch_size,)\n",
    "        np.array: input token type ids in 'int32', shape (batch_size, seq_length)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # convert to unicode\n",
    "        text_a = line[0]\n",
    "        if self._pair:\n",
    "            assert len(line) == 2\n",
    "            text_b = line[1]\n",
    "\n",
    "        tokens_a = self._tokenizer.tokenize(text_a)\n",
    "        tokens_b = None\n",
    "\n",
    "        if self._pair:\n",
    "            tokens_b = self._tokenizer(text_b)\n",
    "\n",
    "        if tokens_b:\n",
    "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "            # length is less than the specified length.\n",
    "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "            self._truncate_seq_pair(tokens_a, tokens_b,\n",
    "                                    self._max_seq_length - 3)\n",
    "        else:\n",
    "            # Account for [CLS] and [SEP] with \"- 2\"\n",
    "            if len(tokens_a) > self._max_seq_length - 2:\n",
    "                tokens_a = tokens_a[0:(self._max_seq_length - 2)]\n",
    "\n",
    "        # The embedding vectors for `type=0` and `type=1` were learned during\n",
    "        # pre-training and are added to the wordpiece embedding vector\n",
    "        # (and position vector). This is not *strictly* necessary since\n",
    "        # the [SEP] token unambiguously separates the sequences, but it makes\n",
    "        # it easier for the model to learn the concept of sequences.\n",
    "\n",
    "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "        # the entire model is fine-tuned.\n",
    "        #vocab = self._tokenizer.vocab\n",
    "        vocab = self._vocab\n",
    "        tokens = []\n",
    "        tokens.append(vocab.cls_token)\n",
    "        tokens.extend(tokens_a)\n",
    "        tokens.append(vocab.sep_token)\n",
    "        segment_ids = [0] * len(tokens)\n",
    "\n",
    "        if tokens_b:\n",
    "            tokens.extend(tokens_b)\n",
    "            tokens.append(vocab.sep_token)\n",
    "            segment_ids.extend([1] * (len(tokens) - len(segment_ids)))\n",
    "\n",
    "        input_ids = self._tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The valid length of sentences. Only real  tokens are attended to.\n",
    "        valid_length = len(input_ids)\n",
    "\n",
    "        if self._pad:\n",
    "            # Zero-pad up to the sequence length.\n",
    "            padding_length = self._max_seq_length - valid_length\n",
    "            # use padding tokens for the rest\n",
    "            input_ids.extend([vocab[vocab.padding_token]] * padding_length)\n",
    "            segment_ids.extend([0] * padding_length)\n",
    "\n",
    "        return np.array(input_ids, dtype='int32'), np.array(valid_length, dtype='int32'),\\\n",
    "            np.array(segment_ids, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1701445055879,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "T2FDY474HBvg"
   },
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len,\n",
    "                 pad, pair):\n",
    "        transform = BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len,vocab=vocab, pad=pad, pair=pair)\n",
    "        #transform = nlp.data.BERTSentenceTransform(\n",
    "        #    tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701445057247,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "-rzBA5eRHJHi",
    "outputId": "60347cf2-6253-478d-f5f3-a2d49cccbb60"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018460512161254883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "tokenizer_config.json",
       "rate": null,
       "total": 432,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c474f9cff6394a2a801e4588acf8137e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017142295837402344,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "spiece.model",
       "rate": null,
       "total": 371427,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e93c23bdaa4db0953035572ad8e3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/371k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017169475555419922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "special_tokens_map.json",
       "rate": null,
       "total": 244,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12448c42ad4c475d91638d01a6a84c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/244 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701445057700,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "SoHDJZ1xHMeZ"
   },
   "outputs": [],
   "source": [
    "# kobert 공식 git에 있는 get_kobert_model 선언\n",
    "def get_kobert_model(model_path, vocab_file, ctx=\"cpu\"):\n",
    "    bertmodel = BertModel.from_pretrained(model_path)\n",
    "    device = torch.device(ctx)\n",
    "    bertmodel.to(device)\n",
    "    bertmodel.eval()\n",
    "    vocab_b_obj = nlp.vocab.BERTVocab.from_sentencepiece(vocab_file,\n",
    "                                                         padding_token='[PAD]')\n",
    "    return bertmodel, vocab_b_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 1989,
     "status": "ok",
     "timestamp": 1701445060536,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "ONzMbMqRHSwQ"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017295122146606445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "config.json",
       "rate": null,
       "total": 535,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00dc0367dc4749969f077b3764e3ac07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/535 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01722550392150879,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "pytorch_model.bin",
       "rate": null,
       "total": 368792544,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d578d76874406eb3ca1de2eaabcf87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/369M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "bertmodel, vocab = get_kobert_model('skt/kobert-base-v1', tokenizer.vocab_file)\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1701445061719,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "h3bgbx49LASq"
   },
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes = 6,   # 6 classes\n",
    "                 dr_rate = None,\n",
    "                 params = None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p = dr_rate)\n",
    "\n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "\n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device),return_dict = False)\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1701445062852,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "V6J1MiEpL8Oz"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PZ5q5qTFVCW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0SKUL7-FVuS"
   },
   "source": [
    "Stratified K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 369,
     "status": "ok",
     "timestamp": 1701445064197,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "ofncJ3ydMDR2"
   },
   "outputs": [],
   "source": [
    "import torch, gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1701445165871,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "n3hROkv4CKSo",
    "outputId": "f1a78c97-5fb0-489e-f21b-14ac6c573dd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " '5대은행 가계대출 한달새 3조5000억 늘어...올 들어 최대 폭         5대 시중은행 가계대출이 10월 한 달간 3조5000억원가량 늘었다. 대출금리가 오르고 있음에도 주택담보대출(주담대)을 중심으로 가계대출 증가폭이 더 커진 모습이다.1일 금융권에 따르면 국민·신한·하나·우리·NH농협 등 국내 5대 은행의 10월 말 가계대출 잔액은 685조7820억원으로 전월(682조3294억원)대비 3조4526억원 늘었다. 가계대출이 증가세로 돌아선 지난 5월 이후 가장 큰 폭이다. 가계대출은 5월 1431억원 6월 6332억원 7월 9754억원 8월 1조5912억워 9월 1조5174억원 증가해왔다.주담대가 크게 늘어난 점이 영향을 미쳤다. 5대 은행의 주담대는 지난달 말 520조9861억원으로 전월(517조858억원)대비 3조1273억원 늘었다. 이날 기준 5대 은행의 주담대 변동금리는 연 4.55~7.18%로 상단이 7%를 넘어섰다. 고정금리도 연 4.39~6.72%로 상단이 7%에 근접한 상태다.2021년 11월 이후 1년 10개월째 감소하던 신용대출도 증가 전환했다. 지난달 말 신용대출 잔액은 107조9490억원으로 전월(107조3409억원)대비 6081억원 늘었다. 전세자금 대출은 10월 말 121조6992억원으로 전월보다 4764억원 줄었다.',\n",
       " 5]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1701445075048,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "ITurORJ6Phfn",
    "outputId": "665a4280-a360-44c6-d624-76d9eef878d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5대은행 가계대출 한달새 3조5000억 늘어...올 들어 최대 폭         5...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>빗썸 부리또 월렛, GBIC 해커톤 대회 성료 [서울=뉴시스]이지영 기자 = 빗썸 ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>농협은행, 연합 플로깅 캠페인으로 ‘ESG’ 실천  NH농협은행(은행장 이석용)은 ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>하나금융, 전 임직원 '모두하나데이'로 ESG 실천  하나금융그룹은 1일 하나금융그...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>윤 대통령이 질타한 '은행 성과급 잔치'는 없었다 최근 수년간 대출 금리 인상 등으...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7195</th>\n",
       "      <td>1910</td>\n",
       "      <td>미국서 2주 이상 실업수당 청구한 사람, 2년 만에 최대         16일(현지...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7196</th>\n",
       "      <td>1912</td>\n",
       "      <td>이스라엘, 알시파 병원에 외신 불러… \"버려진 노트북에 인질 영상\" 주장 팔레스타인...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7197</th>\n",
       "      <td>1913</td>\n",
       "      <td>러 매체, “‘푸틴 신뢰한다’는 한국 청년, 러시아군 자원 입대” 러시아 매체 ‘A...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7198</th>\n",
       "      <td>1914</td>\n",
       "      <td>클린스만호, 싱가포르에 5-0 대승...손흥민 이강인 황희찬 등 공격진 모두 골골골...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>1917</td>\n",
       "      <td>러시아 매체 \"한국 청년, 러시아군 입대… 돈바스 지역 투입\" 러시아 매체가 한국의...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1  2\n",
       "0        3  5대은행 가계대출 한달새 3조5000억 늘어...올 들어 최대 폭         5...  5\n",
       "1        6  빗썸 부리또 월렛, GBIC 해커톤 대회 성료 [서울=뉴시스]이지영 기자 = 빗썸 ...  5\n",
       "2        9  농협은행, 연합 플로깅 캠페인으로 ‘ESG’ 실천  NH농협은행(은행장 이석용)은 ...  5\n",
       "3       13  하나금융, 전 임직원 '모두하나데이'로 ESG 실천  하나금융그룹은 1일 하나금융그...  5\n",
       "4       16  윤 대통령이 질타한 '은행 성과급 잔치'는 없었다 최근 수년간 대출 금리 인상 등으...  5\n",
       "...    ...                                                ... ..\n",
       "7195  1910  미국서 2주 이상 실업수당 청구한 사람, 2년 만에 최대         16일(현지...  4\n",
       "7196  1912  이스라엘, 알시파 병원에 외신 불러… \"버려진 노트북에 인질 영상\" 주장 팔레스타인...  4\n",
       "7197  1913  러 매체, “‘푸틴 신뢰한다’는 한국 청년, 러시아군 자원 입대” 러시아 매체 ‘A...  4\n",
       "7198  1914  클린스만호, 싱가포르에 5-0 대승...손흥민 이강인 황희찬 등 공격진 모두 골골골...  4\n",
       "7199  1917  러시아 매체 \"한국 청년, 러시아군 입대… 돈바스 지역 투입\" 러시아 매체가 한국의...  4\n",
       "\n",
       "[7200 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1701445438589,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "DZL0uSw7Fo6T"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 602)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1701445443420,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "zSvVj2rEKXUm"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1701445444623,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "MA-Y7y57LAXv"
   },
   "outputs": [],
   "source": [
    "max_len = 140\n",
    "batch_size = 8\n",
    "# 130 =0.7 정도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 445,
     "status": "ok",
     "timestamp": 1701445447235,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "Ck9jZtUG8-EC"
   },
   "outputs": [],
   "source": [
    "list_train_idx = []\n",
    "list_test_idx = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(df_cv_data[1], df_cv_data[2]):\n",
    "  list_train_idx.append(train_idx)\n",
    "  list_test_idx.append(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "yUrrD8DB8_xk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01705336570739746,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 720,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f133409bfb4331be6074c57a90f94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 1.6039785146713257 train acc 0.375\n",
      "epoch 1 batch id 201 loss 1.578283667564392 train acc 0.2599502487562189\n",
      "epoch 1 batch id 401 loss 0.9938846230506897 train acc 0.432356608478803\n",
      "epoch 1 batch id 601 loss 1.2086772918701172 train acc 0.5185108153078203\n",
      "epoch 1 train acc 0.5460069444444444\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017107725143432617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 180,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7380cd7cf244f31b5dcfe0288f3ef4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.6638888888888889\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016648292541503906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 720,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a0c8c13ba740688369b693fe391de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.3626064956188202 train acc 0.875\n",
      "epoch 2 batch id 201 loss 1.4289010763168335 train acc 0.7232587064676617\n",
      "epoch 2 batch id 401 loss 1.004494547843933 train acc 0.7175810473815462\n",
      "epoch 2 batch id 601 loss 1.1433840990066528 train acc 0.7196339434276207\n",
      "epoch 2 train acc 0.7201388888888889\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01712322235107422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 180,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584f1e8a11484b0cbbf3fb85ee2a4d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.7222222222222222\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01667022705078125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 720,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1a6d40bfe543868eef49492fb956df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.9529440402984619 train acc 0.625\n",
      "epoch 3 batch id 201 loss 0.4082198739051819 train acc 0.7842039800995025\n",
      "epoch 3 batch id 401 loss 0.14625976979732513 train acc 0.7849127182044888\n",
      "epoch 3 batch id 601 loss 0.670361340045929 train acc 0.7816139767054908\n",
      "epoch 3 train acc 0.7789930555555555\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0171663761138916,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 180,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49acf1fc8ffa4deaac0ff1934c63172b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.7277777777777777\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01632380485534668,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 720,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a5f94bce8d4e4eaaefe2109575653a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.0844910740852356 train acc 1.0\n",
      "epoch 4 batch id 201 loss 0.2319452464580536 train acc 0.8345771144278606\n",
      "epoch 4 batch id 401 loss 0.09534298628568649 train acc 0.831359102244389\n",
      "epoch 4 batch id 601 loss 0.10785331577062607 train acc 0.8361064891846922\n",
      "epoch 4 train acc 0.8342013888888888\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016994237899780273,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 180,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d090bc54d745efb05dae5549611f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.7270833333333333\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016612529754638672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 720,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fb37185f854e87aa37d8aec3657f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 1.7432633638381958 train acc 0.625\n",
      "epoch 5 batch id 201 loss 0.383849173784256 train acc 0.8905472636815921\n",
      "epoch 5 batch id 401 loss 0.45352527499198914 train acc 0.8765586034912718\n",
      "epoch 5 batch id 601 loss 0.050256021320819855 train acc 0.8731281198003328\n",
      "epoch 5 train acc 0.8690972222222222\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017003774642944336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 180,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac104f337994e939db423a7b5a2e76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.7381944444444445\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016812562942504883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 720,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4526ee0d5849fb927c70ee0ab5cacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 batch id 1 loss 0.3511575162410736 train acc 0.875\n",
      "epoch 6 batch id 201 loss 0.035872478038072586 train acc 0.9011194029850746\n",
      "epoch 6 batch id 401 loss 0.2143760472536087 train acc 0.8993142144638404\n",
      "epoch 6 batch id 601 loss 0.028612270951271057 train acc 0.8999584026622296\n",
      "epoch 6 train acc 0.8980902777777777\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018672943115234375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 180,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da08ce709a7499783d8243a1042a0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 test acc 0.7159722222222222\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016701459884643555,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 720,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5061d08ddc4a4bbe43cd6dad9c7176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 batch id 1 loss 0.05592764914035797 train acc 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_89387/1898611787.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m           \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m           \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update learning rate schedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_test_history = []\n",
    "fold = 0\n",
    "\n",
    "\n",
    "for train_idx, test_idx in zip(list_train_idx, list_test_idx):\n",
    "  fold += 1\n",
    "\n",
    "  warmup_ratio = 0.1\n",
    "  num_epochs = 10    ### 에포크 수정 ###\n",
    "  max_grad_norm = 1\n",
    "  log_interval = 200\n",
    "  learning_rate =  5e-5\n",
    "\n",
    "\n",
    "  bertmodel, vocab = get_kobert_model('skt/kobert-base-v1', tokenizer.vocab_file)\n",
    "  model = BERTClassifier(bertmodel,  dr_rate = 0.5).to(device)\n",
    "\n",
    "\n",
    "  train_data = [cv_data[i] for i in train_idx]\n",
    "  test_data = [cv_data[i] for i in test_idx]\n",
    "\n",
    "  train_dataset = BERTDataset(dataset = train_data, sent_idx = 1, label_idx = 2, bert_tokenizer = tokenizer, vocab = vocab, max_len = max_len, pad = True, pair = False)\n",
    "  test_dataset = BERTDataset(dataset = test_data, sent_idx = 1, label_idx = 2, bert_tokenizer = tokenizer, vocab = vocab, max_len = max_len, pad = True, pair = False)\n",
    "\n",
    "  train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "  test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "  no_decay = ['bias', 'LayerNorm.weight']\n",
    "  optimizer_grouped_parameters = [\n",
    "      {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "      {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "  ]\n",
    "\n",
    "  optimizer = AdamW(optimizer_grouped_parameters, lr = learning_rate)\n",
    "  loss_fn = nn.CrossEntropyLoss() # 다중분류를 위한 loss function\n",
    "\n",
    "  t_total = len(train_dataloader) * num_epochs\n",
    "  warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "  scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = warmup_step, num_training_steps = t_total)\n",
    "\n",
    "  train_history = []\n",
    "  test_history = []\n",
    "  loss_history = []\n",
    "\n",
    "  for e in range(num_epochs):\n",
    "      train_acc = 0.0\n",
    "      test_acc = 0.0\n",
    "      model.train()\n",
    "      for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
    "          optimizer.zero_grad()\n",
    "          token_ids = token_ids.long().to(device)\n",
    "          segment_ids = segment_ids.long().to(device)\n",
    "          valid_length= valid_length\n",
    "          label = label.long().to(device)\n",
    "          out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "          # print(label.shape, out.shape)\n",
    "          loss = loss_fn(out, label)\n",
    "          loss.backward()\n",
    "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "          optimizer.step()\n",
    "          scheduler.step()  # Update learning rate schedule\n",
    "          train_acc += calc_accuracy(out, label)\n",
    "          if batch_id % log_interval == 0:\n",
    "              print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "              train_history.append(train_acc / (batch_id+1))\n",
    "              loss_history.append(loss.data.cpu().numpy())\n",
    "      print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "      # train_history.append(train_acc / (batch_id+1))\n",
    "\n",
    "      # .eval() : nn.Module에서 train time과 eval time에서 수행하는 다른 작업을 수행할 수 있도록 switching 하는 함수\n",
    "      # 즉, model이 Dropout이나 BatNorm2d를 사용하는 경우, train 시에는 사용하지만 evaluation을 할 때에는 사용하지 않도록 설정해주는 함수\n",
    "      model.eval()\n",
    "      for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(test_dataloader)):\n",
    "          token_ids = token_ids.long().to(device)\n",
    "          segment_ids = segment_ids.long().to(device)\n",
    "          valid_length = valid_length\n",
    "          label = label.long().to(device)\n",
    "          out = model(token_ids, valid_length, segment_ids)\n",
    "          test_acc += calc_accuracy(out, label)\n",
    "      print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
    "      test_history.append(test_acc / (batch_id+1))\n",
    "\n",
    "\n",
    "\n",
    "  # 모형 가중치 저장\n",
    "  torch.save(model.state_dict(), f'/home2/a301v/myubai/Machine Learning/Model Weights/ArticleWeight{fold}.pth')\n",
    "\n",
    "  list_test_history.append(test_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjKQOKc4AYZI"
   },
   "outputs": [],
   "source": [
    "df_test_history = pd.DataFrame(list_test_history)\n",
    "df_test_history.to_csv('/content/drive/MyDrive/Colab Notebooks/Machine Learning - Graduate/Stratified K-fold CVs/Article Baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1701406043476,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "ShtM1aeHCseE",
    "outputId": "6cb7da6c-fc1d-4e86-d2d5-afef4e47b4c6"
   },
   "outputs": [],
   "source": [
    "df_test_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTwZz4AhEDDU"
   },
   "source": [
    "New Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701445710757,
     "user": {
      "displayName": "윤 이상",
      "userId": "05321719341467468761"
     },
     "user_tz": -540
    },
    "id": "X2GMbgSREOxT",
    "outputId": "466e24df-ef3d-49d3-a4c6-43d4cc55ef4f"
   },
   "outputs": [],
   "source": [
    "new_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNUv_ecpECIp"
   },
   "outputs": [],
   "source": [
    "warmup_ratio = 0.1\n",
    "num_epochs = 3    ### 에포크 수정 ###\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5\n",
    "\n",
    "\n",
    "\n",
    "bertmodel, vocab = get_kobert_model('skt/kobert-base-v1', tokenizer.vocab_file)\n",
    "model = BERTClassifier(bertmodel,  dr_rate = 0.5).to(device)\n",
    "\n",
    "\n",
    "train_data = cv_data\n",
    "test_data = new_data\n",
    "\n",
    "train_dataset = BERTDataset(dataset = train_data, sent_idx = 1, label_idx = 2, bert_tokenizer = tokenizer, vocab = vocab, max_len = max_len, pad = True, pair = False)\n",
    "test_dataset = BERTDataset(dataset = test_data, sent_idx = 1, label_idx = 2, bert_tokenizer = tokenizer, vocab = vocab, max_len = max_len, pad = True, pair = False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr = learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss() # 다중분류를 위한 loss function\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = warmup_step, num_training_steps = t_total)\n",
    "\n",
    "train_history = []\n",
    "test_history = []\n",
    "loss_history = []\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "        # print(label.shape, out.shape)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "            train_history.append(train_acc / (batch_id+1))\n",
    "            loss_history.append(loss.data.cpu().numpy())\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    # train_history.append(train_acc / (batch_id+1))\n",
    "\n",
    "    # .eval() : nn.Module에서 train time과 eval time에서 수행하는 다른 작업을 수행할 수 있도록 switching 하는 함수\n",
    "    # 즉, model이 Dropout이나 BatNorm2d를 사용하는 경우, train 시에는 사용하지만 evaluation을 할 때에는 사용하지 않도록 설정해주는 함수\n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length = valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
    "    test_history.append(test_acc / (batch_id+1))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
